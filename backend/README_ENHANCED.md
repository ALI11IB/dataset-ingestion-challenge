# Enhanced Air Quality Backend API

## üöÄ Performance-Optimized Backend for Large-Scale Data Processing

This enhanced backend is specifically designed to handle large amounts of air quality data efficiently, with comprehensive optimizations for performance, scalability, and maintainability.

## ‚ú® Key Features

### üóÑÔ∏è Database Optimization
- **Strategic Indexing**: Optimized database indexes for fast query performance
- **Connection Pooling**: Efficient PostgreSQL connection management
- **Query Optimization**: Enhanced queries with proper indexing and planning
- **Migration Support**: Database schema versioning and migrations

### üìä Advanced Data Processing
- **Pagination**: Efficient handling of large datasets with configurable page sizes
- **Data Aggregation**: Statistical analysis with hourly, daily, and monthly aggregation
- **Correlation Analysis**: Built-in correlation coefficient calculations
- **Async Processing**: Background job processing for large data operations

### ‚ö° Performance Enhancements
- **Caching Layer**: In-memory caching with configurable TTL
- **Response Compression**: Gzip compression for reduced bandwidth usage
- **Performance Monitoring**: Real-time query performance tracking
- **Slow Query Detection**: Automatic detection and logging of slow queries

### üîí Security & Reliability
- **Security Headers**: Helmet.js integration for API security
- **Input Validation**: Comprehensive request validation
- **Error Handling**: Robust error handling and logging
- **CORS Configuration**: Configurable cross-origin resource sharing

## üõ†Ô∏è Installation & Setup

### Prerequisites
- Node.js 18+ 
- PostgreSQL 12+
- npm or yarn

### Installation
```bash
# Install dependencies
npm install

# Set up environment variables
cp env.example .env

# Configure database connection in .env
DB_HOST=localhost
DB_PORT=5432
DB_USERNAME=postgres
DB_PASSWORD=postgres
DB_DATABASE=air_quality
```

### Database Setup
```bash
# Run database migrations
npm run migration:run

# Or use TypeORM CLI
npx typeorm migration:run
```

### Development
```bash
# Start development server
npm run start:dev

# Build for production
npm run build

# Start production server
npm run start:prod
```

## üì° API Endpoints

### Core Data Endpoints

#### Get Time Series Data (with Pagination)
```http
GET /api/readings/data?parameter=co&startDate=2004-03-01&endDate=2004-03-31&page=1&limit=1000
```

**Response:**
```json
{
  "data": [...],
  "total": 9358,
  "page": 1,
  "totalPages": 10
}
```

#### Get Parameter Statistics
```http
GET /api/readings/statistics/co?aggregation=daily&startDate=2004-03-01&endDate=2004-03-31
```

**Response:**
```json
[
  {
    "period": "2004-03-01T00:00:00.000Z",
    "avg_value": "2.5",
    "min_value": "1.2",
    "max_value": "4.1",
    "count": "24"
  }
]
```

#### Get Parameter Correlation
```http
GET /api/readings/correlation?parameter1=co&parameter2=c6h6&startDate=2004-03-01&endDate=2004-03-31
```

**Response:**
```json
{
  "correlation": 0.75,
  "dataPoints": 744
}
```

#### Get Data Summary
```http
GET /api/readings/summary
```

#### Get Available Parameters
```http
GET /api/readings/parameters
```

#### Upload Data
```http
POST /api/readings/ingest
Content-Type: multipart/form-data

file: [CSV file]
```

## üîß Configuration

### Environment Variables
```env
# Application
NODE_ENV=production
PORT=3001
CORS_ORIGIN=http://localhost:3000

# Database
DB_HOST=localhost
DB_PORT=5432
DB_USERNAME=postgres
DB_PASSWORD=postgres
DB_DATABASE=air_quality

# Performance
CACHE_TTL=300
MAX_PAGE_SIZE=10000
CONNECTION_POOL_SIZE=10
QUERY_TIMEOUT=30000
```

### Performance Tuning
```typescript
// In constants/index.ts
export const DEFAULT_PAGE_SIZE = 1000;
export const MAX_PAGE_SIZE = 10000;
export const CACHE_TTL = 300; // 5 minutes
export const CONNECTION_POOL_SIZE = 10;
```

## üìà Performance Metrics

### Expected Improvements
- **Query Performance**: 60-80% faster with proper indexing
- **Memory Usage**: 40% reduction with pagination
- **Response Time**: 50% improvement with caching
- **Throughput**: 3x increase with connection pooling

### Monitoring
- Query execution times are logged
- Slow queries (>1s) are automatically detected
- Cache hit/miss ratios are tracked
- Connection pool utilization is monitored

## üèóÔ∏è Architecture

### Service Layer
- **ReadingsService**: Core data operations with caching
- **ValidationService**: Data validation and error handling
- **AsyncProcessingService**: Background job processing

### Infrastructure
- **Database**: PostgreSQL with optimized indexes
- **Caching**: In-memory cache with TTL
- **Security**: Helmet.js for security headers
- **Compression**: Gzip compression middleware

### Monitoring
- **Performance Interceptor**: Request/response timing
- **Logger**: Structured logging with different levels
- **Error Handling**: Comprehensive error tracking

## üöÄ Deployment

### Production Checklist
- [ ] Set `NODE_ENV=production`
- [ ] Configure production database
- [ ] Set up connection pooling
- [ ] Enable compression
- [ ] Configure security headers
- [ ] Set up monitoring and logging
- [ ] Run database migrations

### Docker Support
```dockerfile
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY dist ./dist
EXPOSE 3001
CMD ["npm", "run", "start:prod"]
```

## üîç Troubleshooting

### Common Issues

#### Slow Queries
- Check if indexes are properly created
- Monitor query execution plans
- Consider adding more specific indexes

#### Memory Issues
- Reduce `MAX_PAGE_SIZE` for large datasets
- Implement proper pagination in frontend
- Monitor cache usage

#### Connection Issues
- Check connection pool settings
- Monitor database connections
- Consider connection pooling optimization

### Debug Mode
```bash
# Enable debug logging
DEBUG=* npm run start:dev

# Enable TypeORM logging
NODE_ENV=development npm run start:dev
```

## üìö Additional Resources

- [API Documentation](./API_ENHANCEMENTS.md)
- [Database Schema](./src/readings/readings.entity.ts)
- [Performance Monitoring](./src/common/interceptors/performance.interceptor.ts)
- [Configuration Guide](./src/config/)

## ü§ù Contributing

1. Follow the existing code style
2. Add tests for new features
3. Update documentation
4. Ensure performance impact is minimal
5. Test with large datasets

## üìÑ License

This project is part of the OI FullStack Technical Challenge.
